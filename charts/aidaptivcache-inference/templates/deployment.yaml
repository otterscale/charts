apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "aidaptivcache-inference.fullname" . }}
  labels:
    {{- include "aidaptivcache-inference.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.deployment.replicas }}
  selector:
    matchLabels:
      {{- include "aidaptivcache-inference.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "aidaptivcache-inference.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
      - name: vllm-api
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        securityContext:
          {{- toYaml .Values.securityContext | nindent 10 }}
        workingDir: /home/root/aiDAPTIV2/script
        env:
        - name: VLLM_USE_V1
          value: {{ .Values.vllm.env.vllmUseV1 | quote }}
        - name: VLLM_WORKER_MULTIPROC_METHOD
          value: {{ .Values.vllm.env.vllmWorkerMultiprocMethod | quote }}
        - name: TIKTOKEN_ENCODINGS_BASE
          value: {{ .Values.vllm.env.tiktokenEncodingsBase | quote }}
        command:
        - /bin/sh
        - -c
        - |
          {{- if .Values.prescript }}
{{ .Values.prescript | indent 10 }}
          {{- end }}
          python3 vllm_api_server.py \
          --model {{ .Values.vllm.args.model }} \
          --nvme_path {{ .Values.vllm.args.nvmePath }} \
          --port {{ .Values.vllm.args.port }} \
          --gpu-memory-utilization {{ .Values.vllm.args.gpuMemoryUtilization }} \
          --max-model-len {{ .Values.vllm.args.maxModelLen }} \
          --tensor-parallel-size {{ .Values.vllm.args.tensorParallelSize }} \
          --dram-kv-offload-gb {{ .Values.vllm.args.dramKvOffloadGb }} \
          --ssd-kv-offload-gb {{ .Values.vllm.args.ssdKvOffloadGb }} \
          {{- if .Values.vllm.args.noResumeKvCache }}
          --no-resume-kv-cache \
          {{- end }}
          {{- if .Values.vllm.args.disableGpuReuse }}
          --disable-gpu-reuse \
          {{- end }}
          {{- if .Values.vllm.args.enableChunkedPrefill }}
          --enable-chunked-prefill \
          {{- end }}
          {{- if .Values.vllm.args.disableLongToken }}
          --disable-long-token \
          {{- end }}
          {{- if .Values.vllm.args.resumeKvCache }}
          --resume-kv-cache \
          {{- end }}
          {{- if .Values.vllm.args.cleanObsoleteKvCache }}
          --clean-obsolete-kv-cache \
          {{- end }}
          {{- if .Values.vllm.args.enablePrefixCaching }}
          --enable-prefix-caching \
          {{- end }}
          {{- if .Values.vllm.args.enforceEager }}
          --enforce-eager \
          {{- end }}
          {{- if .Values.vllm.lora.enable }}
          --enable-lora \
          --lora-modules {{ .Values.vllm.lora.modules }} \
          --max-lora-rank {{ .Values.vllm.lora.maxRank }} \
          {{- end }}
          {{- if .Values.postscript }}
{{ .Values.postscript | indent 10 }}
          {{- end }}
        ports:
        - containerPort: {{ .Values.service.targetPort }}
          name: http
        resources:
          {{- toYaml .Values.resources | nindent 10 }}
        volumeMounts:
        {{- if .Values.volumes.dshm.enabled }}
        - name: dshm
          mountPath: /dev/shm
        {{- end }}
      volumes:
      {{- if .Values.volumes.dshm.enabled }}
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: {{ .Values.volumes.dshm.sizeLimit }}
      {{- end }}
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
